{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef1434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder, FashionMNIST\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# the following import is required for training to be robust to truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up some parans\n",
    "DATA = './data'\n",
    "RESIZE = (224, 224)\n",
    "BATCH_SIZE = 1\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98efa074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pre-trained ResNet18 \n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "# no need to perform any augmentation other than resizing \n",
    "imageTransformations = transforms.Compose([ \n",
    "        transforms.Resize(RESIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# test on few images downloaded from the internet\n",
    "dataset = ImageFolder(DATA, transform=imageTransformations)\n",
    "                      \n",
    "# define loader\n",
    "imageLoader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b70f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img2Vec():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, model, nFeatures):\n",
    "        \n",
    "        self.model = model\n",
    "        self.nFeatures = nFeatures\n",
    "        self.avgPool = model._modules.get('avgpool')\n",
    "        \n",
    "    def getVec(self, image, device):\n",
    "        \n",
    "        model = self.model\n",
    "        embedding = torch.zeros(1, self.nFeatures, 1, 1)\n",
    "        \n",
    "        def copyData(m, i, o): embedding.copy_(o.data)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            if image.shape[1] == 1: \n",
    "                image = torch.from_numpy(_repeat_grayscale(image))\n",
    "            \n",
    "            # move to GPU\n",
    "            model, image = model.to(device), image.to(device)\n",
    "    \n",
    "            h = self.avgPool.register_forward_hook(copyData)\n",
    "            self.model(image)\n",
    "            h.remove()\n",
    "        \n",
    "        return embedding.numpy()[0, :, 0, 0]\n",
    "    \n",
    "    def _repeat_grayscale(img):\n",
    "        return np.repeat(img[..., np.newaxis], 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32911864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the image vector \n",
    "img2vec = Img2Vec(resnet18, 512)\n",
    "\n",
    "vectors = {}\n",
    "for (img, _) in imageLoader:\n",
    "    vec = img2vec.getVec(img, DEVICE)\n",
    "    vectors[img] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfaf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
